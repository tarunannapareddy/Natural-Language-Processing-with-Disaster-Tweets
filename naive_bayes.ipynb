{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e4b5cb8-1ef7-4830-b16f-f0dcd2cc4d5f",
   "metadata": {},
   "source": [
    "# Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba72601b-3152-4016-b398-759b36a7d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d129005-448d-4a47-9671-8d0a24a3fb14",
   "metadata": {},
   "source": [
    "# Test Naive Bayes with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d0b725-0a96-477b-a6d1-829b9a045906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for xtest data:-\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83      1112\n",
      "           1       0.78      0.70      0.74       792\n",
      "\n",
      "    accuracy                           0.79      1904\n",
      "   macro avg       0.79      0.78      0.78      1904\n",
      "weighted avg       0.79      0.79      0.79      1904\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#load the test and training data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "def test_model(train, test):\n",
    "    #We will use the CountVectorizer function to vectorize and count our data\n",
    "    vector = CountVectorizer()\n",
    "    X = vector.fit_transform(train.text)\n",
    "    Y = train.target.values\n",
    "    P = vector.transform(test.text)\n",
    "\n",
    "    # Now we split the data using 25% test and 75% train \n",
    "    # We use a state of 101 so outputs are consistent after we fine tune\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(X,Y,test_size=0.25,train_size=0.75,random_state=101)\n",
    "\n",
    "    #We plug our sets into the models and print the results\n",
    "    mnb = MultinomialNB()\n",
    "    model_mnb = mnb.fit(xtrain,ytrain)\n",
    "    ts_pred_mnb = model_mnb.predict(xtest)\n",
    "    print(\"Classification report for xtest data:-\\n\\n\",classification_report(ytest,ts_pred_mnb),\"\\n\")\n",
    "    \n",
    "test_model(train_df, test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03419ef-2bed-485e-9c57-a01da5135c08",
   "metadata": {},
   "source": [
    "These results are our baseline. Now lets fine tune and see if we can get better results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e98983-4ad5-4357-933c-62b1b87f8fd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Finetuning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c13826-fd54-4ebb-8d36-7fd7e9f212bb",
   "metadata": {},
   "source": [
    "First lets try taking out stop words and see if this increases the performance of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a5bda78-f762-498e-b1ba-841e4e052da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Our Deeds are the Reason of this #earthquake M...\n",
      "1               Forest fire near La Ronge Sask. Canada\n",
      "2    All residents asked to 'shelter in place' are ...\n",
      "3    13,000 people receive #wildfires evacuation or...\n",
      "4    Just got sent this photo from Ruby #Alaska as ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\",\"vis\"))\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    words = text.split()  # Tokenize the text\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# Apply the function to the \"text\" column and save as a new df\n",
    "train_df_1 = train_df.copy()\n",
    "train_df_1[\"text\"] = train_df[\"text\"].apply(remove_stop_words)\n",
    "print(train_df[\"text\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fce5ce14-85b0-4cfa-9635-7f3a000f560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for xtest data:-\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1112\n",
      "           1       0.76      0.72      0.74       792\n",
      "\n",
      "    accuracy                           0.79      1904\n",
      "   macro avg       0.79      0.78      0.78      1904\n",
      "weighted avg       0.79      0.79      0.79      1904\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(train_df_1, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c911c829-29e8-46a8-bc45-fbb03600d652",
   "metadata": {},
   "source": [
    "Our end goal is to identify tweets that relate to disasters for emergency responders. Therefore, with our model we should aim to have high percision. Recall is less important because it would require knowing whether or not the tweet related to a disaster after the fact which is useless to first responders. So clearly removing stop words did not optimize the data for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00d72691-310b-4d27-a860-b49ce905c9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-: 389\n",
      "via: 115\n",
      "fire: 108\n",
      "...: 106\n",
      "&amp;: 105\n",
      "California: 86\n",
      "killed: 86\n",
      "like: 85\n",
      "people: 83\n",
      "suicide: 71\n",
      "2: 67\n",
      "Hiroshima: 59\n",
      "disaster: 59\n",
      "Northern: 58\n",
      "bombing: 56\n",
      "bomber: 56\n",
      "crash: 55\n",
      "bomb: 55\n",
      "families: 54\n",
      "fires: 53\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_text = \" \".join(train_df_1[train_df_1['target']==1]['text'])\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = all_text.split()\n",
    "\n",
    "# Count the occurrences of each word\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Get the top 20 most common words\n",
    "top_20_words = word_counts.most_common(20)\n",
    "\n",
    "# Print the results\n",
    "for word, count in top_20_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c475b09-d2bd-4ec3-9389-af8355c7d03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with target 1: 3\n",
      " with target 0: 10\n"
     ]
    }
   ],
   "source": [
    "def count_substring_by_target(dataframe, substring):\n",
    "    # Filter the DataFrame based on target values\n",
    "    target_1 = dataframe[dataframe[\"target\"] == 1]\n",
    "    target_0 = dataframe[dataframe[\"target\"] == 0]\n",
    "\n",
    "    # Count occurrences of the substring in the \"text\" column\n",
    "    count_target_1 = target_1[\"text\"].str.count(substring).sum()\n",
    "    count_target_0 = target_0[\"text\"].str.count(substring).sum()\n",
    "\n",
    "    print(f\" with target 1: {count_target_1}\")\n",
    "    print(f\" with target 0: {count_target_0}\")\n",
    "    \n",
    "count_substring_by_target(train_df, \"arsonist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2e621-a782-4759-9018-9e80547cc884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
